{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"collapsed_sections":["rNDYJwYIKmw-","CO8v6QZr5hW1","7Y5nb3B3DcPT","iJijH1Uv8FQP","Cj7ALFQA8FgB","5frcJKhTWvpF","6EyXyefI5Xkz","9KVrX9dP0JK2"],"authorship_tag":"ABX9TyM5oinGodOpM0fQ8t4atnSp"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["\"\"\"\n","Author: Ryleigh J. Bruce\n","Date: June 17, 2024\n","\n","Purpose: Preparing a dataset for fine tuning a YOLO model.\n","\n","\n","Note: The author generated this text in part with GPT-4,\n","OpenAI’s large-scale language-generation model. Upon generating\n","draft code, the authors reviewed, edited, and revised the code\n","to their own liking and takes ultimate responsibility for\n","the content of this code.\n","\n","\"\"\""],"metadata":{"id":"PIOfm1Vf0jRQ"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Module: Mount the Notebook to Google Drive"],"metadata":{"id":"rNDYJwYIKmw-"}},{"cell_type":"markdown","source":["Here we import the drive module that allows us to link the Colab environment with our google drive, where the desired data set is stored. This allows us to access any files located within Google Drive and interact with them directly."],"metadata":{"id":"w6GgQGxBWvFP"}},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"rMnCIhfoNmo8","executionInfo":{"status":"ok","timestamp":1718336592344,"user_tz":300,"elapsed":28999,"user":{"displayName":"Ryleigh Bruce","userId":"04866625339349492872"}},"outputId":"43dd3f7a-29a9-4dc2-b0b8-7b9d6ea44179"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"markdown","source":["# Downloading a Dataset from FiftyOne Data Zoo"],"metadata":{"id":"CO8v6QZr5hW1"}},{"cell_type":"markdown","source":["The FiftyOne Data Zoo is an open-source tool for building and downloading high quality datasets for training machine learning models. Datasets are often preprocessed, minimizing the amount of labor required for preparing the dataset for training. More information about FiftyOne Data Zoo can be found at the following link: https://docs.voxel51.com/user_guide/dataset_zoo/index.html."],"metadata":{"id":"HQ4r4C6U8D6S"}},{"cell_type":"markdown","source":["## Module: Installing the Necessary Libraries"],"metadata":{"id":"7Y5nb3B3DcPT"}},{"cell_type":"markdown","source":["First the FiftyOne library must be installed in the colab environment. This is done using the `!pip install` command."],"metadata":{"id":"RkPFTzy38Etn"}},{"cell_type":"code","source":["!pip install fiftyone"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"a0rYckXuPGC5","executionInfo":{"status":"ok","timestamp":1718645258000,"user_tz":300,"elapsed":68194,"user":{"displayName":"Ryleigh Bruce","userId":"04866625339349492872"}},"outputId":"961ea3ec-62b8-4910-f5bb-b4e09c8f3511"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting fiftyone\n","  Downloading fiftyone-0.24.1-py3-none-any.whl (8.2 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.2/8.2 MB\u001b[0m \u001b[31m15.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting aiofiles (from fiftyone)\n","  Downloading aiofiles-23.2.1-py3-none-any.whl (15 kB)\n","Collecting argcomplete (from fiftyone)\n","  Downloading argcomplete-3.4.0-py3-none-any.whl (42 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.6/42.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: beautifulsoup4 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.12.3)\n","Collecting boto3 (from fiftyone)\n","  Downloading boto3-1.34.127-py3-none-any.whl (139 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m139.2/139.2 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: cachetools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.3.3)\n","Collecting dacite<1.8.0,>=1.6.0 (from fiftyone)\n","  Downloading dacite-1.7.0-py3-none-any.whl (12 kB)\n","Collecting Deprecated (from fiftyone)\n","  Downloading Deprecated-1.2.14-py2.py3-none-any.whl (9.6 kB)\n","Collecting ftfy (from fiftyone)\n","  Downloading ftfy-6.2.0-py3-none-any.whl (54 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m54.4/54.4 kB\u001b[0m \u001b[31m1.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: humanize in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.7.0)\n","Collecting hypercorn>=0.13.2 (from fiftyone)\n","  Downloading hypercorn-0.17.3-py3-none-any.whl (61 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m61.7/61.7 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting Jinja2==3.0.3 (from fiftyone)\n","  Downloading Jinja2-3.0.3-py3-none-any.whl (133 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m133.6/133.6 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting kaleido!=0.2.1.post1 (from fiftyone)\n","  Downloading kaleido-0.2.1-py2.py3-none-manylinux1_x86_64.whl (79.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.9/79.9 MB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: matplotlib in /usr/local/lib/python3.10/dist-packages (from fiftyone) (3.7.1)\n","Collecting mongoengine==0.24.2 (from fiftyone)\n","  Downloading mongoengine-0.24.2-py3-none-any.whl (108 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m108.9/108.9 kB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting motor>=2.5 (from fiftyone)\n","  Downloading motor-3.4.0-py3-none-any.whl (74 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m74.3/74.3 kB\u001b[0m \u001b[31m4.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.25.2)\n","Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from fiftyone) (24.1)\n","Requirement already satisfied: pandas in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2.0.3)\n","Requirement already satisfied: Pillow>=6.2 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (9.4.0)\n","Requirement already satisfied: plotly>=4.14 in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.15.0)\n","Collecting pprintpp (from fiftyone)\n","  Downloading pprintpp-0.4.0-py2.py3-none-any.whl (16 kB)\n","Requirement already satisfied: psutil in /usr/local/lib/python3.10/dist-packages (from fiftyone) (5.9.5)\n","Collecting pymongo>=3.12 (from fiftyone)\n","  Downloading pymongo-4.7.3-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (669 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m669.1/669.1 kB\u001b[0m \u001b[31m7.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: pytz in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2023.4)\n","Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from fiftyone) (6.0.1)\n","Requirement already satisfied: regex in /usr/local/lib/python3.10/dist-packages (from fiftyone) (2024.5.15)\n","Collecting retrying (from fiftyone)\n","  Downloading retrying-1.3.4-py3-none-any.whl (11 kB)\n","Requirement already satisfied: scikit-learn in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.2.2)\n","Requirement already satisfied: scikit-image in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.19.3)\n","Requirement already satisfied: scipy in /usr/local/lib/python3.10/dist-packages (from fiftyone) (1.11.4)\n","Requirement already satisfied: setuptools in /usr/local/lib/python3.10/dist-packages (from fiftyone) (67.7.2)\n","Collecting sseclient-py<2,>=1.7.2 (from fiftyone)\n","  Downloading sseclient_py-1.8.0-py2.py3-none-any.whl (8.8 kB)\n","Collecting sse-starlette<1,>=0.10.3 (from fiftyone)\n","  Downloading sse_starlette-0.10.3-py3-none-any.whl (8.0 kB)\n","Collecting starlette>=0.24.0 (from fiftyone)\n","  Downloading starlette-0.37.2-py3-none-any.whl (71 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m71.9/71.9 kB\u001b[0m \u001b[31m4.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting strawberry-graphql==0.138.1 (from fiftyone)\n","  Downloading strawberry_graphql-0.138.1-py3-none-any.whl (192 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m192.5/192.5 kB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: tabulate in /usr/local/lib/python3.10/dist-packages (from fiftyone) (0.9.0)\n","Collecting xmltodict (from fiftyone)\n","  Downloading xmltodict-0.13.0-py2.py3-none-any.whl (10.0 kB)\n","Collecting universal-analytics-python3<2,>=1.0.1 (from fiftyone)\n","  Downloading universal_analytics_python3-1.1.1-py3-none-any.whl (10 kB)\n","Collecting fiftyone-brain<0.17,>=0.16.1 (from fiftyone)\n","  Downloading fiftyone_brain-0.16.1-py3-none-any.whl (89 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m89.6/89.6 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting fiftyone-db<2.0,>=0.4 (from fiftyone)\n","  Downloading fiftyone_db-1.1.3.tar.gz (7.9 kB)\n","  Installing build dependencies ... \u001b[?25l\u001b[?25hdone\n","  Getting requirements to build wheel ... \u001b[?25l\u001b[?25hdone\n","  Preparing metadata (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","Collecting voxel51-eta<0.13,>=0.12.6 (from fiftyone)\n","  Downloading voxel51_eta-0.12.6-py2.py3-none-any.whl (942 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m942.9/942.9 kB\u001b[0m \u001b[31m61.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: opencv-python-headless in /usr/local/lib/python3.10/dist-packages (from fiftyone) (4.10.0.82)\n","Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from Jinja2==3.0.3->fiftyone) (2.1.5)\n","Collecting graphql-core<3.3.0,>=3.2.0 (from strawberry-graphql==0.138.1->fiftyone)\n","  Downloading graphql_core-3.2.3-py3-none-any.whl (202 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m202.9/202.9 kB\u001b[0m \u001b[31m22.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: python-dateutil<3.0.0,>=2.7.0 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (2.8.2)\n","Requirement already satisfied: typing_extensions<5.0.0,>=3.7.4 in /usr/local/lib/python3.10/dist-packages (from strawberry-graphql==0.138.1->fiftyone) (4.12.2)\n","Requirement already satisfied: exceptiongroup>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (1.2.1)\n","Collecting h11 (from hypercorn>=0.13.2->fiftyone)\n","  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m7.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting h2>=3.1.0 (from hypercorn>=0.13.2->fiftyone)\n","  Downloading h2-4.1.0-py3-none-any.whl (57 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m57.5/57.5 kB\u001b[0m \u001b[31m7.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting priority (from hypercorn>=0.13.2->fiftyone)\n","  Downloading priority-2.0.0-py3-none-any.whl (8.9 kB)\n","Collecting taskgroup (from hypercorn>=0.13.2->fiftyone)\n","  Downloading taskgroup-0.0.0a4-py2.py3-none-any.whl (9.1 kB)\n","Requirement already satisfied: tomli in /usr/local/lib/python3.10/dist-packages (from hypercorn>=0.13.2->fiftyone) (2.0.1)\n","Collecting wsproto>=0.14.0 (from hypercorn>=0.13.2->fiftyone)\n","  Downloading wsproto-1.2.0-py3-none-any.whl (24 kB)\n","Requirement already satisfied: tenacity>=6.2.0 in /usr/local/lib/python3.10/dist-packages (from plotly>=4.14->fiftyone) (8.3.0)\n","Collecting dnspython<3.0.0,>=1.16.0 (from pymongo>=3.12->fiftyone)\n","  Downloading dnspython-2.6.1-py3-none-any.whl (307 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m307.7/307.7 kB\u001b[0m \u001b[31m31.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: anyio<5,>=3.4.0 in /usr/local/lib/python3.10/dist-packages (from starlette>=0.24.0->fiftyone) (3.7.1)\n","Collecting httpx>=0.10.0 (from universal-analytics-python3<2,>=1.0.1->fiftyone)\n","  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting dill (from voxel51-eta<0.13,>=0.12.6->fiftyone)\n","  Downloading dill-0.3.8-py3-none-any.whl (116 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m13.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: future in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (0.18.3)\n","Requirement already satisfied: glob2 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (0.7)\n","Collecting jsonlines (from voxel51-eta<0.13,>=0.12.6->fiftyone)\n","  Downloading jsonlines-4.0.0-py3-none-any.whl (8.7 kB)\n","Collecting py7zr (from voxel51-eta<0.13,>=0.12.6->fiftyone)\n","  Downloading py7zr-0.21.0-py3-none-any.whl (67 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m67.6/67.6 kB\u001b[0m \u001b[31m8.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting rarfile (from voxel51-eta<0.13,>=0.12.6->fiftyone)\n","  Downloading rarfile-4.2-py3-none-any.whl (29 kB)\n","Requirement already satisfied: requests in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (2.31.0)\n","Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (1.16.0)\n","Requirement already satisfied: sortedcontainers in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (2.4.0)\n","Requirement already satisfied: tzlocal in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (5.2)\n","Requirement already satisfied: urllib3 in /usr/local/lib/python3.10/dist-packages (from voxel51-eta<0.13,>=0.12.6->fiftyone) (2.0.7)\n","Requirement already satisfied: soupsieve>1.2 in /usr/local/lib/python3.10/dist-packages (from beautifulsoup4->fiftyone) (2.5)\n","Collecting botocore<1.35.0,>=1.34.127 (from boto3->fiftyone)\n","  Downloading botocore-1.34.127-py3-none-any.whl (12.3 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.3/12.3 MB\u001b[0m \u001b[31m62.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting jmespath<2.0.0,>=0.7.1 (from boto3->fiftyone)\n","  Downloading jmespath-1.0.1-py3-none-any.whl (20 kB)\n","Collecting s3transfer<0.11.0,>=0.10.0 (from boto3->fiftyone)\n","  Downloading s3transfer-0.10.1-py3-none-any.whl (82 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m82.2/82.2 kB\u001b[0m \u001b[31m9.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: wrapt<2,>=1.10 in /usr/local/lib/python3.10/dist-packages (from Deprecated->fiftyone) (1.14.1)\n","Requirement already satisfied: wcwidth<0.3.0,>=0.2.12 in /usr/local/lib/python3.10/dist-packages (from ftfy->fiftyone) (0.2.13)\n","Requirement already satisfied: contourpy>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.2.1)\n","Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (0.12.1)\n","Requirement already satisfied: fonttools>=4.22.0 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (4.53.0)\n","Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (1.4.5)\n","Requirement already satisfied: pyparsing>=2.3.1 in /usr/local/lib/python3.10/dist-packages (from matplotlib->fiftyone) (3.1.2)\n","Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas->fiftyone) (2024.1)\n","Requirement already satisfied: networkx>=2.2 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (3.3)\n","Requirement already satisfied: imageio>=2.4.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2.31.6)\n","Requirement already satisfied: tifffile>=2019.7.26 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (2024.5.22)\n","Requirement already satisfied: PyWavelets>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-image->fiftyone) (1.6.0)\n","Requirement already satisfied: joblib>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (1.4.2)\n","Requirement already satisfied: threadpoolctl>=2.0.0 in /usr/local/lib/python3.10/dist-packages (from scikit-learn->fiftyone) (3.5.0)\n","Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (3.7)\n","Requirement already satisfied: sniffio>=1.1 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.4.0->starlette>=0.24.0->fiftyone) (1.3.1)\n","Collecting hyperframe<7,>=6.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n","  Downloading hyperframe-6.0.1-py3-none-any.whl (12 kB)\n","Collecting hpack<5,>=4.0 (from h2>=3.1.0->hypercorn>=0.13.2->fiftyone)\n","  Downloading hpack-4.0.0-py3-none-any.whl (32 kB)\n","Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone) (2024.6.2)\n","Collecting httpcore==1.* (from httpx>=0.10.0->universal-analytics-python3<2,>=1.0.1->fiftyone)\n","  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: attrs>=19.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonlines->voxel51-eta<0.13,>=0.12.6->fiftyone) (23.2.0)\n","Collecting texttable (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n","  Downloading texttable-1.7.0-py2.py3-none-any.whl (10 kB)\n","Collecting pycryptodomex>=3.16.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n","  Downloading pycryptodomex-3.20.0-cp35-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.1 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.1/2.1 MB\u001b[0m \u001b[31m73.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyzstd>=0.15.9 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n","  Downloading pyzstd-0.16.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (413 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m413.8/413.8 kB\u001b[0m \u001b[31m36.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pyppmd<1.2.0,>=1.1.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n","  Downloading pyppmd-1.1.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (138 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m138.9/138.9 kB\u001b[0m \u001b[31m11.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting pybcj<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n","  Downloading pybcj-1.0.2-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (49 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.7/49.7 kB\u001b[0m \u001b[31m5.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting multivolumefile>=0.2.3 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n","  Downloading multivolumefile-0.2.3-py3-none-any.whl (17 kB)\n","Collecting inflate64<1.1.0,>=1.0.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n","  Downloading inflate64-1.0.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (93 kB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.1/93.1 kB\u001b[0m \u001b[31m10.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hCollecting brotli>=1.1.0 (from py7zr->voxel51-eta<0.13,>=0.12.6->fiftyone)\n","  Downloading Brotli-1.1.0-cp310-cp310-manylinux_2_5_x86_64.manylinux1_x86_64.manylinux_2_12_x86_64.manylinux2010_x86_64.whl (3.0 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.0/3.0 MB\u001b[0m \u001b[31m79.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests->voxel51-eta<0.13,>=0.12.6->fiftyone) (3.3.2)\n","Building wheels for collected packages: fiftyone-db\n","  Building wheel for fiftyone-db (pyproject.toml) ... \u001b[?25l\u001b[?25hdone\n","  Created wheel for fiftyone-db: filename=fiftyone_db-1.1.3-py3-none-manylinux1_x86_64.whl size=42156164 sha256=ef83dd4c9f7e8bf1d3853e1997ec01fb9b415291675ed4e42fd05e4b723599aa\n","  Stored in directory: /root/.cache/pip/wheels/f3/2b/8b/eda0b425855d8b735aadf596af626e4cd9a1555cfefa4c337c\n","Successfully built fiftyone-db\n","Installing collected packages: texttable, sseclient-py, pprintpp, kaleido, brotli, xmltodict, taskgroup, retrying, rarfile, pyzstd, pyppmd, pycryptodomex, pybcj, priority, multivolumefile, jsonlines, jmespath, Jinja2, inflate64, hyperframe, hpack, h11, graphql-core, ftfy, fiftyone-db, dnspython, dill, Deprecated, dacite, argcomplete, aiofiles, wsproto, strawberry-graphql, starlette, pymongo, py7zr, httpcore, h2, botocore, voxel51-eta, sse-starlette, s3transfer, motor, mongoengine, hypercorn, httpx, fiftyone-brain, universal-analytics-python3, boto3, fiftyone\n","  Attempting uninstall: Jinja2\n","    Found existing installation: Jinja2 3.1.4\n","    Uninstalling Jinja2-3.1.4:\n","      Successfully uninstalled Jinja2-3.1.4\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","torch 2.3.0+cu121 requires nvidia-cublas-cu12==12.1.3.1; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cuda-cupti-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cuda-nvrtc-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cuda-runtime-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cudnn-cu12==8.9.2.26; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cufft-cu12==11.0.2.54; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-curand-cu12==10.3.2.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cusolver-cu12==11.4.5.107; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-cusparse-cu12==12.1.0.106; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-nccl-cu12==2.20.5; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\n","torch 2.3.0+cu121 requires nvidia-nvtx-cu12==12.1.105; platform_system == \"Linux\" and platform_machine == \"x86_64\", which is not installed.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed Deprecated-1.2.14 Jinja2-3.0.3 aiofiles-23.2.1 argcomplete-3.4.0 boto3-1.34.127 botocore-1.34.127 brotli-1.1.0 dacite-1.7.0 dill-0.3.8 dnspython-2.6.1 fiftyone-0.24.1 fiftyone-brain-0.16.1 fiftyone-db-1.1.3 ftfy-6.2.0 graphql-core-3.2.3 h11-0.14.0 h2-4.1.0 hpack-4.0.0 httpcore-1.0.5 httpx-0.27.0 hypercorn-0.17.3 hyperframe-6.0.1 inflate64-1.0.0 jmespath-1.0.1 jsonlines-4.0.0 kaleido-0.2.1 mongoengine-0.24.2 motor-3.4.0 multivolumefile-0.2.3 pprintpp-0.4.0 priority-2.0.0 py7zr-0.21.0 pybcj-1.0.2 pycryptodomex-3.20.0 pymongo-4.7.3 pyppmd-1.1.0 pyzstd-0.16.0 rarfile-4.2 retrying-1.3.4 s3transfer-0.10.1 sse-starlette-0.10.3 sseclient-py-1.8.0 starlette-0.37.2 strawberry-graphql-0.138.1 taskgroup-0.0.0a4 texttable-1.7.0 universal-analytics-python3-1.1.1 voxel51-eta-0.12.6 wsproto-1.2.0 xmltodict-0.13.0\n"]}]},{"cell_type":"markdown","source":["Both the `fiftyone` and `fiftyone.zoo` modules must be imported in order to interact with the collection of datasets."],"metadata":{"id":"Zx3nUekJ8FCI"}},{"cell_type":"code","source":["import fiftyone\n","import fiftyone.zoo"],"metadata":{"id":"YJSDdaxU7948"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Module: Loading the Dataset"],"metadata":{"id":"iJijH1Uv8FQP"}},{"cell_type":"markdown","source":["Within the ‘try’ block, the `fiftyone.zoo.load_zoo_dataset()` function is used to load a specified dataset into the `dataset` variable. In this example the script is attempting to download a portion of the COCO dataset. The `split` variable indicates whether the training or validation portion of the dataset should be loaded, and `label_types` defines what types of labels need to be loaded with the dataset. `classes` specifies a subset of classes to be downloaded from the dataset, rather than the entire COCO dataset. This drastically reduces the amount of time required to download the images. `max_samples` allows the user to specify the maximum number of images to be downloaded from the subset."],"metadata":{"id":"xCslgtCVDvji"}},{"cell_type":"markdown","source":["The ‘except’ block ensures that any errors that occur are caught and a corresponding error message is printed along with the exception details."],"metadata":{"id":"HXLRWRudFAfd"}},{"cell_type":"code","source":["try:\n","    dataset = fiftyone.zoo.load_zoo_dataset(\n","      \"coco-2017\", #adjuat this string according to the desired dataset\n","      split=\"train\", #optional\n","      label_types=[\"detections\", \"segmentations\"],\n","      classes=['bird', 'cat', 'dog', 'bear'], #optional\n","      max_samples=3000,\n","    )\n","    print(\"Dataset loaded successfully.\")\n","except Exception as e:\n","    print(f\"Error loading dataset: {e}\")"],"metadata":{"id":"HJ1AYydL5mWM"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Module: Exporting the Dataset"],"metadata":{"id":"Cj7ALFQA8FgB"}},{"cell_type":"markdown","source":["The `export_dir` variable specifies the path for the dataset to be saved."],"metadata":{"id":"sCHDtO3cFPrt"}},{"cell_type":"code","source":["export_dir = \"/content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/coco\""],"metadata":{"id":"y4JxE4lC8AIV"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The export directory path, export format, label field, and split are defined within the ‘try’ block. It is critical to ensure that `dataset_type` is `fiftyone.types.YOLOv5Dataset`, or else the dataset will be unusable for fine tuning the YOLO model. A print statement alerts the user when the script has been successfully completed."],"metadata":{"id":"l_Le7XKX8F61"}},{"cell_type":"markdown","source":["The ‘except’ block ensures that any errors that occur are caught and a corresponding error message is printed along with the exception details."],"metadata":{"id":"tTh2RI2ZKGoP"}},{"cell_type":"markdown","source":["Depending on the volume of images being downloaded the script may take a significant amount of time to complete. If downloading the dataset to Google Drive please allow additional time for the files to actually appear."],"metadata":{"id":"rXfDRLwNKPE4"}},{"cell_type":"code","source":["# Export the dataset in YOLO format\n","try:\n","  dataset.export(\n","    export_dir=export_dir,\n","    dataset_type=fiftyone.types.YOLOv5Dataset,\n","    label_field=\"detections\", # This field specifies where the relevant detection labels are stored\n","    split='train'  # This line is optional unless specifically handling splits differently\n","  )\n","  print(\"Dataset exported successfully.\")\n","except Exception as e:\n","  print(f\"Error exporting dataset: {e}\")"],"metadata":{"id":"pxaiuYam5rAg"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# Splitting the Dataset"],"metadata":{"id":"5frcJKhTWvpF"}},{"cell_type":"markdown","source":["## Module: Downloading the Necessary Libraries"],"metadata":{"id":"frGHozsrTko6"}},{"cell_type":"markdown","source":["In order to sort the dataset into a suitable training and validation split for model finetuning, certain Python libraries will need to be imported. This includes the `os`, `shutil`, `random`, and `logging` modules which provide various crucial functions for interacting with files and debugging."],"metadata":{"id":"Onj3ip6CToFc"}},{"cell_type":"code","source":["import os\n","import shutil\n","import random\n","import logging"],"metadata":{"id":"ozOhKDhSS5r5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["This line of code configures the log that the script uses to keep track of events or changes that occur while the script is running. This specific logging format ensures that the following information is logged: when the event occurred, how important it was, and what the actual event or change was."],"metadata":{"id":"155RmGg4Uhhv"}},{"cell_type":"code","source":["# Configure logging\n","logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')"],"metadata":{"id":"BE78XtmyS1dW"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["Here the paths are configured for the original dataset, as well as the destination files for the images and labels. When finetuning a YOLO model the following file organization is required:\n","\n","```\n","# ├── dataset_directory\n","│   ├── train\n","│   │   ├── images\n","│   │   │   ├── image1.jpg\n","│   │   │   ├── image2.jpg\n","│   │   │   └── ...\n","│   │   └── labels\n","│   │       ├── image1.txt\n","│   │       ├── image2.txt\n","│   │       └── ...\n","│   ├── valid\n","│   │   ├── images\n","│   │   │   ├── image1.jpg\n","│   │   │   ├── image2.jpg\n","│   │   │   └── ...\n","│   │   └── labels\n","│   │       ├── image1.txt\n","│   │       ├── image2.txt\n","│   │       └── ...\n","```\n","It is crucial to ensure that the training and validation files follow this format, or else the finetuning script will not work.\n","\n","`validation_split_percentage = 0.2` ensures that 20% of the dataset is reserved for validation, while the remaining 80% will be used to train the model. This spit percentage can be modified according to the available data and specific requirements of the model, but 0.2 is the standard.\n"],"metadata":{"id":"-M1m7CC5Y1TP"}},{"cell_type":"code","source":["# Paths configuration\n","dataset_path = '/content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/coco-dataset'\n","train_path = '/content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/images/train'\n","val_path = '/content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/images/val'\n","train_labels_path = '/content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/labels/train'\n","val_labels_path = '/content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/labels/val'\n","validation_split_percentage = 0.2"],"metadata":{"id":"fsLOBsaBTRr0"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The `os` module is then used to check that the previously defined directories exist using the `os.makedirs()` function. If the directories do not exist, they are then created."],"metadata":{"id":"RySH5hhuaq2M"}},{"cell_type":"code","source":["# Ensure target directories exist\n","os.makedirs(train_path, exist_ok=True)\n","os.makedirs(val_path, exist_ok=True)\n","os.makedirs(train_labels_path, exist_ok=True)\n","os.makedirs(val_labels_path, exist_ok=True)"],"metadata":{"id":"cRyzGN2hTTWH"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Module: Defining the Sorting Function"],"metadata":{"id":"1b5ceojJy6jg"}},{"cell_type":"markdown","source":["This large code block defines the `sort_data` function for later use. It incorporates several error handling blocks to ensure graceful failure should there be something wrong with the files."],"metadata":{"id":"MxP2EWu7zh7C"}},{"cell_type":"markdown","source":["The `sort_data` function finds the images and their matching label files and randomly shuffles them using the random module imported at the beginning of the script. Then, the files are moved into separate directories for training and validation images and labels. An ‘if’ block is included to print a warning if any images are missing labels."],"metadata":{"id":"XE-HeGjKbHRT"}},{"cell_type":"markdown","source":["For large image datasets this script may take a longer period of time to execute in colab. If the dataset is being sorted into files on Google Drive (as it is in this example) it may take a longer period of time for the images and label files to actually appear in the directories once the script has completed"],"metadata":{"id":"zGb4D-0gd4eg"}},{"cell_type":"code","source":["# Function to sort data into train and validation sets\n","def sort_data(dataset_path, train_path, val_path, train_labels_path, val_labels_path, val_split):\n","    try:\n","        images_path = os.path.join(dataset_path, 'images')\n","        labels_path = os.path.join(dataset_path, 'labels')\n","\n","        image_extensions = ['.png', '.jpg', '.jpeg']\n","        image_files = [f for f in os.listdir(images_path) if os.path.splitext(f)[1].lower() in image_extensions]\n","        label_files = {os.path.splitext(f)[0] for f in os.listdir(labels_path) if f.lower().endswith('.txt')}\n","\n","        matching_files = [os.path.splitext(img)[0] for img in image_files if os.path.splitext(img)[0] in label_files]\n","\n","        random.shuffle(matching_files)\n","        split_index = int(len(matching_files) * (1 - val_split))\n","        train_images = matching_files[:split_index]\n","        val_images = matching_files[split_index:]\n","\n","        missing_labels = [img + '.txt' for img in matching_files if img not in label_files]\n","\n","        for img in train_images:\n","            for ext in image_extensions:\n","                image_file = os.path.join(images_path, img + ext)\n","                if os.path.exists(image_file):\n","                    shutil.move(image_file, os.path.join(train_path, img + ext))\n","                    break  # Break out of the loop once the correct extension is found\n","\n","            label_file = os.path.join(labels_path, img + '.txt')\n","            if os.path.exists(label_file):\n","                shutil.move(label_file, os.path.join(train_labels_path, img + '.txt'))\n","            else:\n","                logging.warning(f\"Label file not found: {label_file}\")\n","\n","        for img in val_images:\n","            for ext in image_extensions:\n","                image_file = os.path.join(images_path, img + ext)\n","                if os.path.exists(image_file):\n","                    shutil.move(image_file, os.path.join(val_path, img + ext))\n","                    break  # Break out of the loop once the correct extension is found\n","\n","            label_file = os.path.join(labels_path, img + '.txt')\n","            if os.path.exists(label_file):\n","                shutil.move(label_file, os.path.join(val_labels_path, img + '.txt'))\n","            else:\n","                logging.warning(f\"Label file not found: {label_file}\")\n","\n","        if missing_labels:\n","            logging.warning(\"Some images are missing label files.\")\n","            logging.warning(f\"Missing labels: {missing_labels}\")\n","        logging.info(\"Data sorted into training and validation directories\")\n","    except Exception as e:\n","        logging.error(f\"An error occurred: {str(e)}\")"],"metadata":{"id":"8-PVGKMhTVC5"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Module: Sorting the Dataset"],"metadata":{"id":"5iDBZnnUd7Ug"}},{"cell_type":"markdown","source":["This block calls the previously defined `sort_data` function with several arguments consisting of the folder directories and validation split defined in an earlier module. When the script has finished sorting the dataset a message is printed to alert the user."],"metadata":{"id":"_MRfQjKSzMwO"}},{"cell_type":"code","source":["if __name__ == \"__main__\":\n","    sort_data(dataset_path, train_path, val_path, train_labels_path, val_labels_path, validation_split_percentage)\n","\n","print('Dataset has been sorted into training and validation folders.')"],"metadata":{"id":"ryq-Z6c85POp","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1718336811704,"user_tz":300,"elapsed":98797,"user":{"displayName":"Ryleigh Bruce","userId":"04866625339349492872"}},"outputId":"312388b3-112b-4c06-924c-dc2c7c2f9572"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Dataset has been sorted into training and validation folders.\n"]}]},{"cell_type":"markdown","source":["# Creating a YAML File"],"metadata":{"id":"6EyXyefI5Xkz"}},{"cell_type":"markdown","source":["## Module: Writing the File Contents"],"metadata":{"id":"9KVrX9dP0JK2"}},{"cell_type":"markdown","source":["In order to successfully train a YOLO model it is crucial to have an accurate .yaml file. This tells the model where to find the training and validation files, the number of classes, and what classes it is looking for. The classes **must** exactly match the ones in the dataset label files or else the model training will fail."],"metadata":{"id":"zSr7cTSh0f6m"}},{"cell_type":"markdown","source":["The content of the .yaml file will be assigned in string format to the `yaml_content` variable."],"metadata":{"id":"ijL9qB4X5dn2"}},{"cell_type":"markdown","source":["`train` and `val` are the paths for the training and validation **image** folders, respectively. If the directory structure specified in the ‘Splitting the Dataset’ section was followed correctly then the model will be able to find the corresponding label folders without the label folder paths being provided."],"metadata":{"id":"156Zg0tl3SJX"}},{"cell_type":"markdown","source":["`nc` is the total number of classes contained in the dataset. In this example, a custom deer dataset has been aggregated with the coco dataset yielding a total of 80 classes. Despite this, in the label files the deer class is labeled as ‘79’ as the list of class names starts at ‘0’."],"metadata":{"id":"dFC4DrPW3XMa"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"hxMrLHKDNdWS"},"outputs":[],"source":["yaml_content = \"\"\"\n","train: /content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/images/train\n","val: /content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/images/val\n","nc: 80\n","names: ['dog', 'person', 'bench', 'potted plant', 'dining table', 'cup', 'knife', 'spoon',\n","        'cake', 'book', 'umbrella', 'handbag', 'bird', 'cell phone', 'car', 'tie', 'backpack',\n","        'traffic light', 'teddy bear', 'chair', 'clock', 'parking meter', 'elephant', 'cow',\n","        'boat', 'skateboard', 'baseball bat', 'baseball glove', 'bottle', 'truck', 'couch',\n","        'tennis racket', 'sports ball', 'fork', 'vase', 'zebra', 'horse', 'train', 'surfboard',\n","        'bus', 'fire hydrant', 'frisbee', 'suitcase', 'cat', 'bowl', 'bicycle', 'motorcycle',\n","        'airplane', 'tv', 'stop sign', 'laptop', 'wine glass', 'microwave', 'sink',\n","        'refrigerator', 'giraffe', 'sheep', 'broccoli', 'banana', 'oven', 'apple', 'orange',\n","        'kite', 'snowboard', 'remote', 'pizza', 'bed', 'skis', 'donut', 'sandwich', 'hot dog',\n","        'bear', 'toaster', 'scissors', 'toilet', 'toothbrush', 'carrot', 'mouse', 'keyboard',\n","        'deer']\n","\"\"\""]},{"cell_type":"markdown","source":["`yaml_path` is simply the path to where the finished .yaml file will be saved."],"metadata":{"id":"b848t3h90aEG"}},{"cell_type":"code","source":["# Change this path to where you want to save the YAML file in your Google Drive\n","yaml_path = '/content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/coco-deer-training.yaml'"],"metadata":{"id":"lgq9C9E60Ryi"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["The script begins by opening a file at the path defined in the `yaml_path` variable using the `open()` function. The `‘w’` in the argument indicates that the file has been opened for writing, and the file object is assigned to the `f` variable. `f.write(yaml_content)` calls the object f to write the `yaml_content` string to the opened file. The file is automatically closed once the ‘with’ block is exited."],"metadata":{"id":"n5I2lynT0Zny"}},{"cell_type":"markdown","source":["Once the file is closed a print statement indicates where the .yaml file has been saved."],"metadata":{"id":"-oOmvmqz5rRa"}},{"cell_type":"code","source":["with open(yaml_path, 'w') as f:\n","    f.write(yaml_content)\n","\n","print(f\"YAML file saved to {yaml_path}\")"],"metadata":{"id":"v5azxG3z0YFk"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["## Module: Checking the YAML File"],"metadata":{"id":"Xz2INMzLWw2i"}},{"cell_type":"markdown","source":["If desired, the .yaml file can be loaded in order to check its contents. First the `yaml` library must be imported."],"metadata":{"id":"5dXc_ORo5vHC"}},{"cell_type":"markdown","source":["The `open()` function is used again to open a file at the `yaml_path`, but rather than creating a new file it opens the newly created .yaml file. The `‘r’` specifies that the file has been opened for reading, and `as f` creates a file object f. `yaml.safe_load` reads the content of the file and converts it to a Python dictionary or a list (depending on the file contents). The `safe_load` method ensures that only simple Python objects are allowed, preventing potentially dangerous .yaml files from being opened."],"metadata":{"id":"_gxBqNx_7Ydb"}},{"cell_type":"code","source":["import yaml\n","with open(yaml_path, 'r') as f:\n","    loaded_yaml = yaml.safe_load(f)\n","print(loaded_yaml)"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Lo7FWzodAAhI","executionInfo":{"status":"ok","timestamp":1718336987173,"user_tz":300,"elapsed":220,"user":{"displayName":"Ryleigh Bruce","userId":"04866625339349492872"}},"outputId":"ca84b8ba-c476-473b-ec52-d4390da4e9fd"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["{'train': '/content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/images/train', 'val': '/content/drive/MyDrive/shared-data/Notebook datafiles/Finetuning-YOLOv5-animals/images/val', 'nc': 80, 'names': ['dog', 'person', 'bench', 'potted plant', 'dining table', 'cup', 'knife', 'spoon', 'cake', 'book', 'umbrella', 'handbag', 'bird', 'cell phone', 'car', 'tie', 'backpack', 'traffic light', 'teddy bear', 'chair', 'clock', 'parking meter', 'elephant', 'cow', 'boat', 'skateboard', 'baseball bat', 'baseball glove', 'bottle', 'truck', 'couch', 'tennis racket', 'sports ball', 'fork', 'vase', 'zebra', 'horse', 'train', 'surfboard', 'bus', 'fire hydrant', 'frisbee', 'suitcase', 'cat', 'bowl', 'bicycle', 'motorcycle', 'airplane', 'tv', 'stop sign', 'laptop', 'wine glass', 'microwave', 'sink', 'refrigerator', 'giraffe', 'sheep', 'broccoli', 'banana', 'oven', 'apple', 'orange', 'kite', 'snowboard', 'remote', 'pizza', 'bed', 'skis', 'donut', 'sandwich', 'hot dog', 'bear', 'toaster', 'scissors', 'toilet', 'toothbrush', 'carrot', 'mouse', 'keyboard', 'deer']}\n"]}]}]}